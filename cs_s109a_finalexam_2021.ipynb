{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://github.com/Harvard-IACS/2021-s109a/blob/master/lectures/crest.png?raw=true\"> CS-S109A Introduction to Data Science \n",
    "\n",
    "## Final Exam: COVID-19 Modeling\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Summer 2021**<br/>\n",
    "**Instructors**: Kevin Rader\n",
    "\n",
    "\n",
    "<hr style='height:2px'>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- This final exam is to be completed indivudally.  Do not consult with your peers when working on it (you can aks the teaching staff for clarification questions, including private messages on Ed).\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list.\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is excessively long because output was not suppressed or otherwise limited. \n",
    "\n",
    "**Note: for all problems, it is up to you to decide how to transform the data (standardization, log transformations, etc.).  Be sure you use and interpret theses transformations approporiately.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# You are free to use any functions/methods within these packages (BS4, ELI5, and LIME are fine too)\n",
    "# if you would like to use any other, please contact hte teaching staff "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the recent spread of COVID-19 \n",
    "\n",
    "![](fig/vaccine.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are tasked with using the COVID case and vaccination data across counties presented by the CDC to analyze the recent surge in COVID infections and the association with (amonth other predictors).  You are also tasked with building prediction models to forecast how the disease spread will change based on data from the previous week (and  demographic and other measures.\n",
    "\n",
    "The exam broken into 4 problems:\n",
    "- Problem 1: Data Wrangling and Explorations\n",
    "- Problem 2: Interpretive Linear Regression Modeling\n",
    "- Problem 3: Prediction Modeling\n",
    "- Problem 4: Further Analysis\n",
    "\n",
    "You are provided with four raw data files, and a 5th cleaned file is provided to be used for all EDA and modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables included in each of the four raw data sets are:\n",
    "\n",
    "For 'covid_cases_county.csv' (note: counties show up many times in this dataset: once for each data they report the number of cases):\n",
    "- `date`: the date of the measurement, taken weekly\n",
    "- `county`: county name\n",
    "- `state`: the state in which the county lies\n",
    "- `fips`: the unique Federal Information Processing System (FIPS) codes for the county\n",
    "- `cases`: the cumulative number of confirmed positive cases up to and including that date\n",
    "- `deaths`: the cumulative number of confirmed COVID-related deaths up to and including that date\n",
    "\n",
    "\n",
    "For 'vaccines_county.csv' (note: counties show up many times in this dataset: once for each data they report the number of cases):\n",
    "- `date`: the date of the measurement, taken weekly\n",
    "- `fips`: the unique FIPS code for the county\n",
    "- `fully`: the percent of residents that are fully vaccinated in the county on that date\n",
    "- `dose1`: the percent of residents that have received at least one vaccine dose in the county on that date.\n",
    "\n",
    "For 'masks_county.csv' (note: this is based on a survey conducted by the New York Times in summer of 2020):\n",
    "- `fips`: the unique FIPS code for the county\n",
    "- `never`: the percent of respondents that report they never wore masks in public\n",
    "- `rarely`: the percent of respondents that report they rarely wore masks in public\n",
    "- `sometimes`: the percent of respondents that report they sometimes wore masks in public\t\n",
    "- `frequently`: the percent of respondents that report they frequently wore masks in public\t\n",
    "- `always`: the percent of respondents that report they always wore masks in public\n",
    "\n",
    "For 'demographics_county.csv' (note: these are various measures taken from 2010 to 2020):\n",
    "- `fips`: the unique FIPS code for the county\n",
    "- `population`: total number of residents in the country\t\n",
    "- `hispanic`: the percentage of residents that self-identify as hispanic\n",
    "- `minority`: the percentage of residents that self-identify as a minority group (non-white)\n",
    "- `female`: the percentage of residents that self-identify as female\n",
    "- `unemployed`: the percentage of residents that are unemployed\n",
    "- `income`: the median household income, in thousnads of dollards\n",
    "- `nodegree`: the percentage of residents that report not having graduated high school\n",
    "- `bachelor`: the percentage of residents that report having a college degree\n",
    "- `inactivity`: the percentage of residents that get less than 1 hour of vigorous exercise a week\n",
    "- `obesity`: the percentage of residents that are considered obese based on BMI\n",
    "- `density`: the population density (residents per square mile)\n",
    "- `votergap20`: Biden voting percentage minus Trump voting percentage in the 2020 election\n",
    "- `votergap16`: Clinton voting percentage minus Trump voting percentage in the 2016 election\n",
    "\n",
    "\n",
    "### Data Sources\n",
    "- Vaccinations [here](https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-County/8xkx-amqh).\n",
    "- Cases [here](https://github.com/nytimes/covid-19-data).\n",
    "- Mask Usage [here](https://github.com/nytimes/covid-19-data/tree/master/mask-use).\n",
    "- Demographics [here](https://www.ers.usda.gov/data-products/county-level-data-sets/) \n",
    "- 2020 Election [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 [25pts]: Data Wrangling and Explorations </b></div>\n",
    "\n",
    "**1.1** Load the data sets as follows:\n",
    "- 'covid_cases_county.csv' as `covid_raw` \n",
    "- 'vaccines_county.csv' as `vaccines_raw`\n",
    "- 'masks_county.csv' as `masks`\n",
    "- 'demographics_county.csv' as `demo` \n",
    "\n",
    "**1.2** Create a subset of the `covid_raw` data frame that only contains the measures for 5 dates: June 27 and July 4, 11, 18 and 25.  Do the same for the `vaccines_raw`.  Call these subsets `covid` and `vaccines`, respectively, and print out their dimensions (aka, shapes).\n",
    "\n",
    "**1.3** Determine and print the number of counties that are measured for each time period in `covid` and `vaccines` (do not print out the list of counties, just the number/count).  Comment on what this implies for presence of missing data.\n",
    "\n",
    "**1.4** Process both `covid` and `vaccines` so that each county is represented by a single row in each data frame (rather than having 5 separate rows for each county: 1 for each time period in part 1.2).  Call these new generate Pandas data frames `covid_by_county` and `vaccines_by_county` separately.  Print out the dimensions of each resulting data frame, and view the header of `covid_by_county`.  Note: you should use informative names for the columns in the resulting data frames: for example, `cases_w30` for the cumulative number of cases on July 25 (it's the 30th week of the calendar year).\n",
    "\n",
    "**Hint**: Splitting based on dates and then using `pd.DataFrame.merge` (source)[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html] could be helpful for this task using the `fips` code as the keys to join on (you should drop any counties that are not measured in all time periods...the default argument for `how` in `pd.DataFrame.merge` will behave this way).\n",
    "\n",
    "**1.5** Merge the 4 data fames (`covid_by_county`, `vaccines_by_county`, `masks`, and `demo`) based on `fips` and save the result as `covid_merged` (you should drop any counties that are not measured in all 4 data frames).  Determine and report how many counties were dropped from `demo` in this process, and view the header of `covid_merged`.\n",
    "\n",
    "**1.6** Use `covid_merged` to calculate the novel case rate (per 1000 residents) for each of the weeks for all of the counties, and save these as 4 new well-named variables in `covid_merged`.  For example, `rate_w30` can mathematically be represented as `1000*(cases_30-cases_29)/population`.  Plot the histogram of the novel case rate in week 29, `rate_w29`, and comment on what you notice.\n",
    "\n",
    "**1.7** We did the steps above (and some other minimal processing) and saved the results in `covid_clean.csv` for you.  Use this data file to answer some exploratory questions and all future analyses: \n",
    "\n",
    "1. Has the overall average case rate increased from week 28 (July 5-11) to week 29 (July 12-18)?  \n",
    "2. Treating the counties as separate and equal observations: in what states did the case rate increase the most?  In what states did the case rate decrease the most (or increse the least)?  List the top 5 for each.  Do you notice any patterns in these states?\n",
    "3. Create and interpret separate visuals to display how the country case rate in week 29 relates to each of the following variables. Interpret what you see (be specific to this domain).\n",
    "\n",
    "    a. The political views in the county (as measured by the votergap in the 2020 election).\n",
    "    \n",
    "    b. The vaccination rate in the county (for week 28) (be sure to throw away the zeros as these represent unreported values).\n",
    "    \n",
    "    c. The population density of the county.\n",
    "    \n",
    "    d. Whether 50% or more of the surveyed residents in the county report that they always wore a mask in public at the time of the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Load the data sets as follows:\n",
    "- 'covid_cases_county.csv' as `covid_raw` \n",
    "- 'vaccines_county.csv' as `vaccines_raw`\n",
    "- 'masks_county.csv' as `masks`\n",
    "- 'demographics_county.csv' as `demo` \n",
    "\n",
    "Print out each of their dimensions (aka, shapes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of covid_raw is (97394, 6)\n",
      "The shape of vaccines_raw is (96720, 4)\n",
      "The shape of masks is (3142, 6)\n",
      "The shape of demo is (3114, 14)\n"
     ]
    }
   ],
   "source": [
    "# Saving data sets\n",
    "covid_raw = pd.read_csv('data/covid_cases_county.csv')\n",
    "vaccines_raw = pd.read_csv('data/vaccines_county.csv')\n",
    "masks = pd.read_csv('data/masks_county.csv')\n",
    "demo = pd.read_csv('data/demographics_county.csv')\n",
    "\n",
    "# Printing dimentions\n",
    "print(f'The shape of covid_raw is {covid_raw.shape}')\n",
    "print(f'The shape of vaccines_raw is {vaccines_raw.shape}')\n",
    "print(f'The shape of masks is {masks.shape}')\n",
    "print(f'The shape of demo is {demo.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Create a subset of the `covid_raw` data frame that only contains the measures for 5 dates: June 27 and July 4, 11, 18 and 25.  Do the same for the `vaccines_raw`.  Call these subsets `covid` and `vaccines`, respectively, and print out their dimensions (aka, shapes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subset for specified dates:\n",
    "covid = covid_raw[(covid_raw['date']=='2021-06-27') | \n",
    "                  (covid_raw['date']=='2021-07-04') | \n",
    "                  (covid_raw['date']=='2021-07-11') |\n",
    "                  (covid_raw['date']=='2021-07-18') | \n",
    "                  (covid_raw['date']=='2021-07-25')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of covid is (16227, 6)\n",
      "The shape of vaccines is (16120, 4)\n"
     ]
    }
   ],
   "source": [
    "# Doing the same for vaccines_raw:\n",
    "vaccines = vaccines_raw[(vaccines_raw['date']=='2021-06-27') | \n",
    "                  (vaccines_raw['date']=='2021-07-04') | \n",
    "                  (vaccines_raw['date']=='2021-07-11') |\n",
    "                  (vaccines_raw['date']=='2021-07-18') | \n",
    "                  (vaccines_raw['date']=='2021-07-25')]\n",
    "\n",
    "# Printing dimentions\n",
    "print(f'The shape of covid is {covid.shape}')\n",
    "print(f'The shape of vaccines is {vaccines.shape}')\n",
    "# vaccines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Determine and print the number of counties that are measured for each time period in `covid` and `vaccines` (do not print out the list of counties, just the number/count).  Comment on what this implies for presence of missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40033.0,\n",
       " 40035.0,\n",
       " 40037.0,\n",
       " 40039.0,\n",
       " 40041.0,\n",
       " 40043.0,\n",
       " 40045.0,\n",
       " 40047.0,\n",
       " 40049.0,\n",
       " 40051.0,\n",
       " 40053.0,\n",
       " 40055.0,\n",
       " 40057.0,\n",
       " 40059.0,\n",
       " 40061.0,\n",
       " 40063.0,\n",
       " 40065.0,\n",
       " 40067.0,\n",
       " 40069.0,\n",
       " 40071.0,\n",
       " 40073.0,\n",
       " 40075.0,\n",
       " 40077.0,\n",
       " 40079.0,\n",
       " 40081.0,\n",
       " 40083.0,\n",
       " 40085.0,\n",
       " 40087.0,\n",
       " 40089.0,\n",
       " 40091.0,\n",
       " 40093.0,\n",
       " 40095.0,\n",
       " 40097.0,\n",
       " 40099.0,\n",
       " 40101.0,\n",
       " 40103.0,\n",
       " 40105.0,\n",
       " 40107.0,\n",
       " 40109.0,\n",
       " 40111.0,\n",
       " 40113.0,\n",
       " 40115.0,\n",
       " 40117.0,\n",
       " 40119.0,\n",
       " 40121.0,\n",
       " 40123.0,\n",
       " 40125.0,\n",
       " 40127.0,\n",
       " 40129.0,\n",
       " 40131.0,\n",
       " 40133.0,\n",
       " 40135.0,\n",
       " 40137.0,\n",
       " 40139.0,\n",
       " 40141.0,\n",
       " 40143.0,\n",
       " 40145.0,\n",
       " 40147.0,\n",
       " 40149.0,\n",
       " 40151.0,\n",
       " 40153.0,\n",
       " 41001.0,\n",
       " 41003.0,\n",
       " 41005.0,\n",
       " 41007.0,\n",
       " 41009.0,\n",
       " 41011.0,\n",
       " 41013.0,\n",
       " 41015.0,\n",
       " 41017.0,\n",
       " 41019.0,\n",
       " 41021.0,\n",
       " 41023.0,\n",
       " 41025.0,\n",
       " 41027.0,\n",
       " 41029.0,\n",
       " 41031.0,\n",
       " 41033.0,\n",
       " 41035.0,\n",
       " 41037.0,\n",
       " 41039.0,\n",
       " 41041.0,\n",
       " 41043.0,\n",
       " 41045.0,\n",
       " 41047.0,\n",
       " 41049.0,\n",
       " 41051.0,\n",
       " 41053.0,\n",
       " 41055.0,\n",
       " 41057.0,\n",
       " 41059.0,\n",
       " 41061.0,\n",
       " 41063.0,\n",
       " 41065.0,\n",
       " 41067.0,\n",
       " 41069.0,\n",
       " 41071.0,\n",
       " 42001.0,\n",
       " 42003.0,\n",
       " 42005.0,\n",
       " 42007.0,\n",
       " 42009.0,\n",
       " 42011.0,\n",
       " 42013.0,\n",
       " 42015.0,\n",
       " 42017.0,\n",
       " 42019.0,\n",
       " 42021.0,\n",
       " 42023.0,\n",
       " 42025.0,\n",
       " 42027.0,\n",
       " 42029.0,\n",
       " 42031.0,\n",
       " 42033.0,\n",
       " 42035.0,\n",
       " 42037.0,\n",
       " 42039.0,\n",
       " 42041.0,\n",
       " 42043.0,\n",
       " 42045.0,\n",
       " 42047.0,\n",
       " 42049.0,\n",
       " 42051.0,\n",
       " 42053.0,\n",
       " 42055.0,\n",
       " 42057.0,\n",
       " 42059.0,\n",
       " 42061.0,\n",
       " 42063.0,\n",
       " 42065.0,\n",
       " 42067.0,\n",
       " 42069.0,\n",
       " 42071.0,\n",
       " 42073.0,\n",
       " 42075.0,\n",
       " 42077.0,\n",
       " 42079.0,\n",
       " 42081.0,\n",
       " 42083.0,\n",
       " 42085.0,\n",
       " 42087.0,\n",
       " 42089.0,\n",
       " 42091.0,\n",
       " 42093.0,\n",
       " 42095.0,\n",
       " 42097.0,\n",
       " 42099.0,\n",
       " 42101.0,\n",
       " 42103.0,\n",
       " 42105.0,\n",
       " 42107.0,\n",
       " 42109.0,\n",
       " 42111.0,\n",
       " 42113.0,\n",
       " 42115.0,\n",
       " 42117.0,\n",
       " 42119.0,\n",
       " 42121.0,\n",
       " 42123.0,\n",
       " 42125.0,\n",
       " 42127.0,\n",
       " 42129.0,\n",
       " 42131.0,\n",
       " 42133.0,\n",
       " 44001.0,\n",
       " 44003.0,\n",
       " 44005.0,\n",
       " 44007.0,\n",
       " 44009.0,\n",
       " 45001.0,\n",
       " 45003.0,\n",
       " 45005.0,\n",
       " 45007.0,\n",
       " 45009.0,\n",
       " 45011.0,\n",
       " 45013.0,\n",
       " 45015.0,\n",
       " 45017.0,\n",
       " 45019.0,\n",
       " 45021.0,\n",
       " 45023.0,\n",
       " 45025.0,\n",
       " 45027.0,\n",
       " 45029.0,\n",
       " 45031.0,\n",
       " 45033.0,\n",
       " 45035.0,\n",
       " 45037.0,\n",
       " 45039.0,\n",
       " 45041.0,\n",
       " 45043.0,\n",
       " 45045.0,\n",
       " 45047.0,\n",
       " 45049.0,\n",
       " 45051.0,\n",
       " 45053.0,\n",
       " 45055.0,\n",
       " 45057.0,\n",
       " 45059.0,\n",
       " 45061.0,\n",
       " 45063.0,\n",
       " 45065.0,\n",
       " 45067.0,\n",
       " 45069.0,\n",
       " 45071.0,\n",
       " 45073.0,\n",
       " 45075.0,\n",
       " 45077.0,\n",
       " 45079.0,\n",
       " 45081.0,\n",
       " 45083.0,\n",
       " 45085.0,\n",
       " 45087.0,\n",
       " 45089.0,\n",
       " 45091.0,\n",
       " 46003.0,\n",
       " 46005.0,\n",
       " 46007.0,\n",
       " 46009.0,\n",
       " 46011.0,\n",
       " 46013.0,\n",
       " 46015.0,\n",
       " 46017.0,\n",
       " 46019.0,\n",
       " 46021.0,\n",
       " 46023.0,\n",
       " 46025.0,\n",
       " 46027.0,\n",
       " 46029.0,\n",
       " 46031.0,\n",
       " 46033.0,\n",
       " 46035.0,\n",
       " 46037.0,\n",
       " 46039.0,\n",
       " 46041.0,\n",
       " 46043.0,\n",
       " 46045.0,\n",
       " 46047.0,\n",
       " 46049.0,\n",
       " 46051.0,\n",
       " 46053.0,\n",
       " 46055.0,\n",
       " 46057.0,\n",
       " 46059.0,\n",
       " 46061.0,\n",
       " 46063.0,\n",
       " 46065.0,\n",
       " 46067.0,\n",
       " 46069.0,\n",
       " 46071.0,\n",
       " 46073.0,\n",
       " 46075.0,\n",
       " 46077.0,\n",
       " 46079.0,\n",
       " 46081.0,\n",
       " 46083.0,\n",
       " 46085.0,\n",
       " 46087.0,\n",
       " 46089.0,\n",
       " 46091.0,\n",
       " 46093.0,\n",
       " 46095.0,\n",
       " 46097.0,\n",
       " 46099.0,\n",
       " 46101.0,\n",
       " 46102.0,\n",
       " 46103.0,\n",
       " 46105.0,\n",
       " 46107.0,\n",
       " 46109.0,\n",
       " 46111.0,\n",
       " 46115.0,\n",
       " 46117.0,\n",
       " 46119.0,\n",
       " 46121.0,\n",
       " 46123.0,\n",
       " 46125.0,\n",
       " 46127.0,\n",
       " 46129.0,\n",
       " 46135.0,\n",
       " 46137.0,\n",
       " 47001.0,\n",
       " 47003.0,\n",
       " 47005.0,\n",
       " 47007.0,\n",
       " 47009.0,\n",
       " 47011.0,\n",
       " 47013.0,\n",
       " 47015.0,\n",
       " 47017.0,\n",
       " 47019.0,\n",
       " 47021.0,\n",
       " 47023.0,\n",
       " 47025.0,\n",
       " 47027.0,\n",
       " 47029.0,\n",
       " 47031.0,\n",
       " 47033.0,\n",
       " 47035.0,\n",
       " 47037.0,\n",
       " 47039.0,\n",
       " 47041.0,\n",
       " 47043.0,\n",
       " 47045.0,\n",
       " 47047.0,\n",
       " 47049.0,\n",
       " 47051.0,\n",
       " 47053.0,\n",
       " 47055.0,\n",
       " 47057.0,\n",
       " 47059.0,\n",
       " 47061.0,\n",
       " 47063.0,\n",
       " 47065.0,\n",
       " 47067.0,\n",
       " 47069.0,\n",
       " 47071.0,\n",
       " 47073.0,\n",
       " 47075.0,\n",
       " 47077.0,\n",
       " 47079.0,\n",
       " 47081.0,\n",
       " 47083.0,\n",
       " 47085.0,\n",
       " 47087.0,\n",
       " 47089.0,\n",
       " 47091.0,\n",
       " 47093.0,\n",
       " 47095.0,\n",
       " 47097.0,\n",
       " 47099.0,\n",
       " 47101.0,\n",
       " 47103.0,\n",
       " 47105.0,\n",
       " 47107.0,\n",
       " 47109.0,\n",
       " 47111.0,\n",
       " 47113.0,\n",
       " 47115.0,\n",
       " 47117.0,\n",
       " 47119.0,\n",
       " 47121.0,\n",
       " 47123.0,\n",
       " 47125.0,\n",
       " 47127.0,\n",
       " 47129.0,\n",
       " 47131.0,\n",
       " 47133.0,\n",
       " 47135.0,\n",
       " 47137.0,\n",
       " 47139.0,\n",
       " 47141.0,\n",
       " 47143.0,\n",
       " 47145.0,\n",
       " 47147.0,\n",
       " 47149.0,\n",
       " 47151.0,\n",
       " 47153.0,\n",
       " 47155.0,\n",
       " 47157.0,\n",
       " 47159.0,\n",
       " 47161.0,\n",
       " 47163.0,\n",
       " 47165.0,\n",
       " 47167.0,\n",
       " 47169.0,\n",
       " 47171.0,\n",
       " 47173.0,\n",
       " 47175.0,\n",
       " 47177.0,\n",
       " 47179.0,\n",
       " 47181.0,\n",
       " 47183.0,\n",
       " 47185.0,\n",
       " 47187.0,\n",
       " 47189.0,\n",
       " 48001.0,\n",
       " 48003.0,\n",
       " 48005.0,\n",
       " 48007.0,\n",
       " 48009.0,\n",
       " 48011.0,\n",
       " 48013.0,\n",
       " 48015.0,\n",
       " 48017.0,\n",
       " 48019.0,\n",
       " 48021.0,\n",
       " 48023.0,\n",
       " 48025.0,\n",
       " 48027.0,\n",
       " 48029.0,\n",
       " 48031.0,\n",
       " 48033.0,\n",
       " 48035.0,\n",
       " 48037.0,\n",
       " 48039.0,\n",
       " 48041.0,\n",
       " 48043.0,\n",
       " 48045.0,\n",
       " 48047.0,\n",
       " 48049.0,\n",
       " 48051.0,\n",
       " 48053.0,\n",
       " 48055.0,\n",
       " 48057.0,\n",
       " 48059.0,\n",
       " 48061.0,\n",
       " 48063.0,\n",
       " 48065.0,\n",
       " 48067.0,\n",
       " 48069.0,\n",
       " 48071.0,\n",
       " 48073.0,\n",
       " 48075.0,\n",
       " 48077.0,\n",
       " 48079.0,\n",
       " 48081.0,\n",
       " 48083.0,\n",
       " 48085.0,\n",
       " 48087.0,\n",
       " 48089.0,\n",
       " 48091.0,\n",
       " 48093.0,\n",
       " 48095.0,\n",
       " 48097.0,\n",
       " 48099.0,\n",
       " 48101.0,\n",
       " 48103.0,\n",
       " 48105.0,\n",
       " 48107.0,\n",
       " 48109.0,\n",
       " 48111.0,\n",
       " 48113.0,\n",
       " 48115.0,\n",
       " 48117.0,\n",
       " 48119.0,\n",
       " 48121.0,\n",
       " 48123.0,\n",
       " 48125.0,\n",
       " 48127.0,\n",
       " 48129.0,\n",
       " 48131.0,\n",
       " 48133.0,\n",
       " 48135.0,\n",
       " 48137.0,\n",
       " 48139.0,\n",
       " 48141.0,\n",
       " 48143.0,\n",
       " 48145.0,\n",
       " 48147.0,\n",
       " 48149.0,\n",
       " 48151.0,\n",
       " 48153.0,\n",
       " 48155.0,\n",
       " 48157.0,\n",
       " 48159.0,\n",
       " 48161.0,\n",
       " 48163.0,\n",
       " 48165.0,\n",
       " 48167.0,\n",
       " 48169.0,\n",
       " 48171.0,\n",
       " 48173.0,\n",
       " 48175.0,\n",
       " 48177.0,\n",
       " 48179.0,\n",
       " 48181.0,\n",
       " 48183.0,\n",
       " 48185.0,\n",
       " 48187.0,\n",
       " 48189.0,\n",
       " 48191.0,\n",
       " 48193.0,\n",
       " 48195.0,\n",
       " 48197.0,\n",
       " 48199.0,\n",
       " 48201.0,\n",
       " 48203.0,\n",
       " 48205.0,\n",
       " 48207.0,\n",
       " 48209.0,\n",
       " 48211.0,\n",
       " 48213.0,\n",
       " 48215.0,\n",
       " 48217.0,\n",
       " 48219.0,\n",
       " 48221.0,\n",
       " 48223.0,\n",
       " 48225.0,\n",
       " 48227.0,\n",
       " 48229.0,\n",
       " 48231.0,\n",
       " 48233.0,\n",
       " 48235.0,\n",
       " 48237.0,\n",
       " 48239.0,\n",
       " 48241.0,\n",
       " 48243.0,\n",
       " 48245.0,\n",
       " 48247.0,\n",
       " 48249.0,\n",
       " 48251.0,\n",
       " 48253.0,\n",
       " 48255.0,\n",
       " 48257.0,\n",
       " 48259.0,\n",
       " 48261.0,\n",
       " 48263.0,\n",
       " 48265.0,\n",
       " 48267.0,\n",
       " 48269.0,\n",
       " 48271.0,\n",
       " 48273.0,\n",
       " 48275.0,\n",
       " 48277.0,\n",
       " 48279.0,\n",
       " 48281.0,\n",
       " 48283.0,\n",
       " 48285.0,\n",
       " 48287.0,\n",
       " 48289.0,\n",
       " 48291.0,\n",
       " 48293.0,\n",
       " 48295.0,\n",
       " 48297.0,\n",
       " 48299.0,\n",
       " 48301.0,\n",
       " 48303.0,\n",
       " 48305.0,\n",
       " 48307.0,\n",
       " 48309.0,\n",
       " 48311.0,\n",
       " 48313.0,\n",
       " 48315.0,\n",
       " 48317.0,\n",
       " 48319.0,\n",
       " 48321.0,\n",
       " 48323.0,\n",
       " 48325.0,\n",
       " 48327.0,\n",
       " 48329.0,\n",
       " 48331.0,\n",
       " 48333.0,\n",
       " 48335.0,\n",
       " 48337.0,\n",
       " 48339.0,\n",
       " 48341.0,\n",
       " 48343.0,\n",
       " 48345.0,\n",
       " 48347.0,\n",
       " 48349.0,\n",
       " 48351.0,\n",
       " 48353.0,\n",
       " 48355.0,\n",
       " 48357.0,\n",
       " 48359.0,\n",
       " 48361.0,\n",
       " 48363.0,\n",
       " 48365.0,\n",
       " 48367.0,\n",
       " 48369.0,\n",
       " 48371.0,\n",
       " 48373.0,\n",
       " 48375.0,\n",
       " 48377.0,\n",
       " 48379.0,\n",
       " 48381.0,\n",
       " 48383.0,\n",
       " 48385.0,\n",
       " 48387.0,\n",
       " 48389.0,\n",
       " 48391.0,\n",
       " 48393.0,\n",
       " 48395.0,\n",
       " 48397.0,\n",
       " 48399.0,\n",
       " 48401.0,\n",
       " 48403.0,\n",
       " 48405.0,\n",
       " 48407.0,\n",
       " 48409.0,\n",
       " 48411.0,\n",
       " 48413.0,\n",
       " 48415.0,\n",
       " 48417.0,\n",
       " 48419.0,\n",
       " 48421.0,\n",
       " 48423.0,\n",
       " 48425.0,\n",
       " 48427.0,\n",
       " 48429.0,\n",
       " 48431.0,\n",
       " 48433.0,\n",
       " 48435.0,\n",
       " 48437.0,\n",
       " 48439.0,\n",
       " 48441.0,\n",
       " 48443.0,\n",
       " 48445.0,\n",
       " 48447.0,\n",
       " 48449.0,\n",
       " 48451.0,\n",
       " 48453.0,\n",
       " 48455.0,\n",
       " 48457.0,\n",
       " 48459.0,\n",
       " 48461.0,\n",
       " 48463.0,\n",
       " 48465.0,\n",
       " 48467.0,\n",
       " 48469.0,\n",
       " 48471.0,\n",
       " 48473.0,\n",
       " 48475.0,\n",
       " 48477.0,\n",
       " 48479.0,\n",
       " 48481.0,\n",
       " 48483.0,\n",
       " 48485.0,\n",
       " 48487.0,\n",
       " 48489.0,\n",
       " 48491.0,\n",
       " 48493.0,\n",
       " 48495.0,\n",
       " 48497.0,\n",
       " 48499.0,\n",
       " 48501.0,\n",
       " 48503.0,\n",
       " 48505.0,\n",
       " 48507.0,\n",
       " 49001.0,\n",
       " 49003.0,\n",
       " 49005.0,\n",
       " 49007.0,\n",
       " 49009.0,\n",
       " 49011.0,\n",
       " 49013.0,\n",
       " 49015.0,\n",
       " 49017.0,\n",
       " 49019.0,\n",
       " 49021.0,\n",
       " 49023.0,\n",
       " 49025.0,\n",
       " 49027.0,\n",
       " 49029.0,\n",
       " 49031.0,\n",
       " 49033.0,\n",
       " 49035.0,\n",
       " 49037.0,\n",
       " 49039.0,\n",
       " 49041.0,\n",
       " 49043.0,\n",
       " 49045.0,\n",
       " 49047.0,\n",
       " 49049.0,\n",
       " 49051.0,\n",
       " 49053.0,\n",
       " 49055.0,\n",
       " 49057.0,\n",
       " 50001.0,\n",
       " 50003.0,\n",
       " 50005.0,\n",
       " 50007.0,\n",
       " 50009.0,\n",
       " 50011.0,\n",
       " 50013.0,\n",
       " 50015.0,\n",
       " 50017.0,\n",
       " 50019.0,\n",
       " 50021.0,\n",
       " 50023.0,\n",
       " 50025.0,\n",
       " 50027.0,\n",
       " 51001.0,\n",
       " 51003.0,\n",
       " 51005.0,\n",
       " 51007.0,\n",
       " 51009.0,\n",
       " 51011.0,\n",
       " 51013.0,\n",
       " 51015.0,\n",
       " 51017.0,\n",
       " 51019.0,\n",
       " 51021.0,\n",
       " 51023.0,\n",
       " 51025.0,\n",
       " 51027.0,\n",
       " 51029.0,\n",
       " 51031.0,\n",
       " 51033.0,\n",
       " 51035.0,\n",
       " 51036.0,\n",
       " 51037.0,\n",
       " 51041.0,\n",
       " 51043.0,\n",
       " 51045.0,\n",
       " 51047.0,\n",
       " 51049.0,\n",
       " 51051.0,\n",
       " 51053.0,\n",
       " 51057.0,\n",
       " 51059.0,\n",
       " 51061.0,\n",
       " 51063.0,\n",
       " 51065.0,\n",
       " 51067.0,\n",
       " 51069.0,\n",
       " 51071.0,\n",
       " 51073.0,\n",
       " 51075.0,\n",
       " 51077.0,\n",
       " 51079.0,\n",
       " 51081.0,\n",
       " 51083.0,\n",
       " 51085.0,\n",
       " 51087.0,\n",
       " 51089.0,\n",
       " 51091.0,\n",
       " 51093.0,\n",
       " 51095.0,\n",
       " 51097.0,\n",
       " 51099.0,\n",
       " 51101.0,\n",
       " 51103.0,\n",
       " 51105.0,\n",
       " 51107.0,\n",
       " 51109.0,\n",
       " 51111.0,\n",
       " 51113.0,\n",
       " 51115.0,\n",
       " 51117.0,\n",
       " 51119.0,\n",
       " 51121.0,\n",
       " 51125.0,\n",
       " 51127.0,\n",
       " 51131.0,\n",
       " 51133.0,\n",
       " 51135.0,\n",
       " 51137.0,\n",
       " 51139.0,\n",
       " 51141.0,\n",
       " 51143.0,\n",
       " 51145.0,\n",
       " 51147.0,\n",
       " 51149.0,\n",
       " 51153.0,\n",
       " 51155.0,\n",
       " 51157.0,\n",
       " 51159.0,\n",
       " 51161.0,\n",
       " 51163.0,\n",
       " 51165.0,\n",
       " 51167.0,\n",
       " 51169.0,\n",
       " 51171.0,\n",
       " 51173.0,\n",
       " 51175.0,\n",
       " 51177.0,\n",
       " 51179.0,\n",
       " 51181.0,\n",
       " 51183.0,\n",
       " 51185.0,\n",
       " 51187.0,\n",
       " 51191.0,\n",
       " 51193.0,\n",
       " 51195.0,\n",
       " 51197.0,\n",
       " 51199.0,\n",
       " 51510.0,\n",
       " 51520.0,\n",
       " 51530.0,\n",
       " 51540.0,\n",
       " 51550.0,\n",
       " 51570.0,\n",
       " 51580.0,\n",
       " 51590.0,\n",
       " 51595.0,\n",
       " 51600.0,\n",
       " 51610.0,\n",
       " 51620.0,\n",
       " 51630.0,\n",
       " 51640.0,\n",
       " 51650.0,\n",
       " 51660.0,\n",
       " 51670.0,\n",
       " 51678.0,\n",
       " 51680.0,\n",
       " 51683.0,\n",
       " 51685.0,\n",
       " 51690.0,\n",
       " 51700.0,\n",
       " 51710.0,\n",
       " 51720.0,\n",
       " 51730.0,\n",
       " 51735.0,\n",
       " 51740.0,\n",
       " 51750.0,\n",
       " 51760.0,\n",
       " 51770.0,\n",
       " 51775.0,\n",
       " 51790.0,\n",
       " 51800.0,\n",
       " 51810.0,\n",
       " 51820.0,\n",
       " 51830.0,\n",
       " 51840.0,\n",
       " 53001.0,\n",
       " 53003.0,\n",
       " 53005.0,\n",
       " 53007.0,\n",
       " 53009.0,\n",
       " 53011.0,\n",
       " 53013.0,\n",
       " 53015.0,\n",
       " 53017.0,\n",
       " 53019.0,\n",
       " 53021.0,\n",
       " 53023.0,\n",
       " 53025.0,\n",
       " 53027.0,\n",
       " 53029.0,\n",
       " 53031.0,\n",
       " 53033.0,\n",
       " 53035.0,\n",
       " 53037.0,\n",
       " 53039.0,\n",
       " 53041.0,\n",
       " 53043.0,\n",
       " 53045.0,\n",
       " 53047.0,\n",
       " 53049.0,\n",
       " 53051.0,\n",
       " 53053.0,\n",
       " 53055.0,\n",
       " 53057.0,\n",
       " 53059.0,\n",
       " 53061.0,\n",
       " 53063.0,\n",
       " 53065.0,\n",
       " 53067.0,\n",
       " 53069.0,\n",
       " 53071.0,\n",
       " 53073.0,\n",
       " 53075.0,\n",
       " 53077.0,\n",
       " 54001.0,\n",
       " 54003.0,\n",
       " 54005.0,\n",
       " 54007.0,\n",
       " 54009.0,\n",
       " 54011.0,\n",
       " 54013.0,\n",
       " 54015.0,\n",
       " 54017.0,\n",
       " 54019.0,\n",
       " 54021.0,\n",
       " 54023.0,\n",
       " 54025.0,\n",
       " 54027.0,\n",
       " 54029.0,\n",
       " 54031.0,\n",
       " 54033.0,\n",
       " 54035.0,\n",
       " 54037.0,\n",
       " 54039.0,\n",
       " 54041.0,\n",
       " 54043.0,\n",
       " 54045.0,\n",
       " 54047.0,\n",
       " 54049.0,\n",
       " 54051.0,\n",
       " 54053.0,\n",
       " 54055.0,\n",
       " 54057.0,\n",
       " 54059.0,\n",
       " 54061.0,\n",
       " 54063.0,\n",
       " 54065.0,\n",
       " 54067.0,\n",
       " 54069.0,\n",
       " 54071.0,\n",
       " 54073.0,\n",
       " 54075.0,\n",
       " 54077.0,\n",
       " 54079.0,\n",
       " 54081.0,\n",
       " 54083.0,\n",
       " 54085.0,\n",
       " 54087.0,\n",
       " 54089.0,\n",
       " 54091.0,\n",
       " 54093.0,\n",
       " 54095.0,\n",
       " 54097.0,\n",
       " 54099.0,\n",
       " 54101.0,\n",
       " 54103.0,\n",
       " 54105.0,\n",
       " 54107.0,\n",
       " 54109.0,\n",
       " 55001.0,\n",
       " 55003.0,\n",
       " 55005.0,\n",
       " 55007.0,\n",
       " 55009.0,\n",
       " 55011.0,\n",
       " 55013.0,\n",
       " 55015.0,\n",
       " 55017.0,\n",
       " 55019.0,\n",
       " 55021.0,\n",
       " 55023.0,\n",
       " 55025.0,\n",
       " 55027.0,\n",
       " 55029.0,\n",
       " 55031.0,\n",
       " 55033.0,\n",
       " 55035.0,\n",
       " 55037.0,\n",
       " 55039.0,\n",
       " 55041.0,\n",
       " 55043.0,\n",
       " 55045.0,\n",
       " 55047.0,\n",
       " 55049.0,\n",
       " 55051.0,\n",
       " 55053.0,\n",
       " 55055.0,\n",
       " 55057.0,\n",
       " 55059.0,\n",
       " 55061.0,\n",
       " 55063.0,\n",
       " 55065.0,\n",
       " 55067.0,\n",
       " 55069.0,\n",
       " 55071.0,\n",
       " 55073.0,\n",
       " 55075.0,\n",
       " 55077.0,\n",
       " 55078.0,\n",
       " 55079.0,\n",
       " 55081.0,\n",
       " 55083.0,\n",
       " 55085.0,\n",
       " 55087.0,\n",
       " 55089.0,\n",
       " 55091.0,\n",
       " 55093.0,\n",
       " 55095.0,\n",
       " 55097.0,\n",
       " 55099.0,\n",
       " 55101.0,\n",
       " 55103.0,\n",
       " 55105.0,\n",
       " 55107.0,\n",
       " 55109.0,\n",
       " 55111.0,\n",
       " 55113.0,\n",
       " 55115.0,\n",
       " 55117.0,\n",
       " 55119.0,\n",
       " 55121.0,\n",
       " 55123.0,\n",
       " 55125.0,\n",
       " 55127.0,\n",
       " 55129.0,\n",
       " 55131.0,\n",
       " 55133.0,\n",
       " 55135.0,\n",
       " 55137.0,\n",
       " 55139.0,\n",
       " 55141.0,\n",
       " 56001.0,\n",
       " 56003.0,\n",
       " 56005.0,\n",
       " 56007.0,\n",
       " 56009.0,\n",
       " 56011.0,\n",
       " 56013.0,\n",
       " 56015.0,\n",
       " 56017.0,\n",
       " 56019.0,\n",
       " 56021.0,\n",
       " 56023.0,\n",
       " 56025.0,\n",
       " 56027.0,\n",
       " 56029.0,\n",
       " 56031.0,\n",
       " 56033.0,\n",
       " 56035.0,\n",
       " 56037.0,\n",
       " 56039.0,\n",
       " 56041.0,\n",
       " 56043.0,\n",
       " 56045.0,\n",
       " 69110.0,\n",
       " 69120.0,\n",
       " 78010.0,\n",
       " 78020.0,\n",
       " 78030.0]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "list(np.unique(covid_by_county.fips))[-1000:]\n",
    "# len(covid[covid['date']=='2021-07-18'].fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90992</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>313</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91082</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3093</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91217</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1176</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91222</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91287</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Florida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91436</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3036</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91452</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Guam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9446</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91593</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91785</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>455</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92078</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>394</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92124</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92141</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47434</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92222</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>749</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92305</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>575</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92448</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Joplin</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7224</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92449</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47015</td>\n",
       "      <td>609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92657</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92691</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92712</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92775</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>962484</td>\n",
       "      <td>33484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92954</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93041</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93122</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2722</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93302</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5630</td>\n",
       "      <td>2561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93314</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12023</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93515</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7594</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93802</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Utah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1225</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93819</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date         county          state  fips   cases   deaths\n",
       "90992  2021-07-18        Unknown         Alaska   NaN     313      0.0\n",
       "91082  2021-07-18        Unknown       Arkansas   NaN    3093      0.0\n",
       "91217  2021-07-18        Unknown    Connecticut   NaN    1176      1.0\n",
       "91222  2021-07-18        Unknown       Delaware   NaN     227      0.0\n",
       "91287  2021-07-18        Unknown        Florida   NaN       3   1422.0\n",
       "91436  2021-07-18        Unknown        Georgia   NaN    3036      6.0\n",
       "91452  2021-07-18        Unknown           Guam   NaN    9446    143.0\n",
       "91593  2021-07-18        Unknown       Illinois   NaN       0    440.0\n",
       "91785  2021-07-18        Unknown           Iowa   NaN     455      0.0\n",
       "92078  2021-07-18        Unknown      Louisiana   NaN     394      0.0\n",
       "92124  2021-07-18        Unknown       Maryland   NaN       0     16.0\n",
       "92141  2021-07-18        Unknown  Massachusetts   NaN   47434     12.0\n",
       "92222  2021-07-18        Unknown       Michigan   NaN     749     16.0\n",
       "92305  2021-07-18        Unknown      Minnesota   NaN     575     93.0\n",
       "92448  2021-07-18         Joplin       Missouri   NaN    7224    117.0\n",
       "92449  2021-07-18    Kansas City       Missouri   NaN   47015    609.0\n",
       "92657  2021-07-18        Unknown       Nebraska   NaN      66      0.0\n",
       "92691  2021-07-18        Unknown  New Hampshire   NaN     307      1.0\n",
       "92712  2021-07-18        Unknown     New Jersey   NaN     826      0.0\n",
       "92775  2021-07-18  New York City       New York   NaN  962484  33484.0\n",
       "92954  2021-07-18        Unknown   North Dakota   NaN      31     31.0\n",
       "93041  2021-07-18        Unknown           Ohio   NaN       0      3.0\n",
       "93122  2021-07-18        Unknown       Oklahoma   NaN    2722      0.0\n",
       "93302  2021-07-18        Unknown    Puerto Rico   NaN    5630   2561.0\n",
       "93314  2021-07-18        Unknown   Rhode Island   NaN   12023     10.0\n",
       "93515  2021-07-18        Unknown      Tennessee   NaN    7594     95.0\n",
       "93802  2021-07-18        Unknown           Utah   NaN    1225     27.0\n",
       "93819  2021-07-18        Unknown        Vermont   NaN      20      0.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of counties in the covid set is:\n",
      " 3218 at date 2021-06-27\n",
      " 3218 at date 2021-07-04\n",
      " 3218 at date 2021-07-11\n",
      " 3218 at date 2021-07-18\n",
      " 3218 at date 2021-07-25\n"
     ]
    }
   ],
   "source": [
    "# There are many cointies names that appears in several states. Therefore we need to use the fips column to identify the \n",
    "#number of unique counties for both sets.\n",
    "\n",
    "# Printing the number of counties for each date in covid, incase one date has less counties:\n",
    "dates = ['2021-06-27','2021-07-04','2021-07-11','2021-07-18','2021-07-25']\n",
    "print('The number of counties in the covid set is:')\n",
    "for d in dates:\n",
    "    nrCounties = len(covid.fips[covid['date']==d].value_counts())  \n",
    "    print(f' {nrCounties} at date {d}')\n",
    "# Choosing not to remove null values yet, and using value_counts to get the number of real values for fips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of counties in the vaccines set is:\n",
      " 3224 at date 2021-06-27\n",
      " 3224 at date 2021-07-04\n",
      " 3224 at date 2021-07-11\n",
      " 3224 at date 2021-07-18\n",
      " 3224 at date 2021-07-25\n"
     ]
    }
   ],
   "source": [
    "# The number of counties in vaccines:\n",
    "print('The number of counties in the vaccines set is:')\n",
    "for d in dates:\n",
    "    nrFips = len(vaccines.fips[vaccines['date']==d].value_counts())\n",
    "    print(f' {nrFips} at date {d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer 1.3:\n",
    "The vaccines set has 3224 counties while covid has 3218.\n",
    "This is because the data sets are also including counties in Puerto Rico, Virgin Islands, Northern Mariana and Guam. If you were to only count the 50 states of US you would get 3218-83= 3135 counties for the covid set and 3224-82= 3142 counties in the vaccines set. The number for the vaccines set is almost the same as wikipedias number of counties for the 50 states of US (3143 in 2020), while the covid set is missing 7 more counties. Three of the missing counties have the state column filled, and can be identified as York City, Cansas City and Joplin. These should be added in if we want to use this for prediction or EDA, especially New York City because of its large population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** Process both `covid` and `vaccines` so that each county is represented by a single row in each data frame (rather than having 5 separate rows for each county: 1 for each time period in part 1.2).  Call these new generate Pandas data frames `covid_by_county` and `vaccines_by_county` separately.  Print out the dimensions of each resulting data frame, and view the header of `covid_by_county`.  Note: you should use informative names for the columns in the resulting data frames: for example, `cases_w30` for the cumulative number of cases on July 25 (it's the 30th week of the calendar year).\n",
    "\n",
    "**Hint**: Splitting based on dates and then using `pd.DataFrame.merge` (source)[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html] could be helpful for this task using the `fips` code as the keys to join on (you should drop any counties that are not measured in all time periods...the default argument for `how` in `pd.DataFrame.merge` will behave this way).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of vaccines_by_county is (3223, 11)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into separate ones for each week:\n",
    "w26 = vaccines[vaccines['date']=='2021-06-27'].dropna()\n",
    "w27 = vaccines[vaccines['date']=='2021-07-04'].dropna()\n",
    "w28 = vaccines[vaccines['date']=='2021-07-11'].dropna()\n",
    "w29 = vaccines[vaccines['date']=='2021-07-18'].dropna()\n",
    "w30 = vaccines[vaccines['date']=='2021-07-25'].dropna()\n",
    "   # Forsk p  gjre mergen med for loop. Delete:\n",
    "# listV = [w30, w29, w28, w27, w26]\n",
    "# newd = pd.DataFrame(0, index=np.arange(len(w30)),columns=i in range())#, columns='ert')\n",
    "# for i, dataframe in range(1):#enumerate(liste):\n",
    "#     if i != 4:\n",
    "#         newd[:,1+i:1+i*3] = dataframe.merge(liste[i+1], on='fips', how='inner')\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "mergedV = w26.merge(w27.merge(w28.merge(w29.merge(w30,on='fips'),on='fips'),on='fips'),on='fips')\n",
    "mergedV.pop('date')\n",
    "mergedV.pop('date_x')\n",
    "mergedV.pop('date_y')\n",
    "vaccines_by_county=mergedV.rename(columns={'fully'  :'fully_w26','dose1'  :'dose1_w26',\n",
    "                                           'fully_x':'fully_w27','dose1_x':'dose1_w27',\n",
    "                                           'fully_y':'fully_w28','dose1_y':'dose1_w28',\n",
    "                                           'fully_x':'fully_w29','dose1_x':'dose1_w29',\n",
    "                                           'fully_y':'fully_w30','dose1_y':'dose1_w30'})\n",
    "\n",
    "print(f'The shape of vaccines_by_county is {vaccines_by_county.shape}')\n",
    "# vaccines_by_county.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of vaccines_by_county is (3223, 11)\n",
      "The shape of covid_by_county is (3140, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases_c26</th>\n",
       "      <th>deaths_c26</th>\n",
       "      <th>cases_c29</th>\n",
       "      <th>deaths_c29</th>\n",
       "      <th>cases_c30</th>\n",
       "      <th>deaths_c30</th>\n",
       "      <th>cases_c29</th>\n",
       "      <th>deaths_c29</th>\n",
       "      <th>cases_c30</th>\n",
       "      <th>deaths_c30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [county, state, fips, cases_c26, deaths_c26, cases_c29, deaths_c29, cases_c30, deaths_c30, cases_c29, deaths_c29, cases_c30, deaths_c30]\n",
       "Index: []"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same for the covid set:\n",
    "c26 = covid[covid['date']=='2021-06-27'].dropna()\n",
    "c27 = covid[covid['date']=='2021-07-04'].dropna()\n",
    "c28 = covid[covid['date']=='2021-07-11'].dropna()\n",
    "c29 = covid[covid['date']=='2021-07-18'].dropna()\n",
    "c30 = covid[covid['date']=='2021-07-25'].dropna()\n",
    "\n",
    "mergedC = c26.merge(c27.merge(c28.merge(c29.merge(c30,on='fips'),on='fips'),on='fips'),on='fips')\n",
    "mergedC.pop('date')\n",
    "mergedC.pop('date_x')\n",
    "mergedC.pop('date_y')\n",
    "mergedC.pop('state_x')\n",
    "mergedC.pop('state_y')\n",
    "mergedC.pop('county_x')\n",
    "mergedC.pop('county_y')\n",
    "\n",
    "covid_by_county=mergedC.rename(columns={'cases'  :'cases_c26','deaths'  :'deaths_c26',\n",
    "                                        'cases_x':'cases_c27','deaths_x':'deaths_c27',\n",
    "                                        'cases_y':'cases_c28','deaths_y':'deaths_c28',\n",
    "                                        'cases_x':'cases_c29','deaths_x':'deaths_c29',\n",
    "                                        'cases_y':'cases_c30','deaths_y':'deaths_c30'})\n",
    "\n",
    "print(f'The shape of vaccines_by_county is {vaccines_by_county.shape}')\n",
    "print(f'The shape of covid_by_county is {covid_by_county.shape}')\n",
    "covid_by_county.head(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer 1.4:\n",
    "Some counties, including all the counties from Puerto Rico and Guam has been dropped from the covid_by_county set because there were missing values, while the vaccines_by_county kept most counties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5** Merge the 4 data fames (`covid_by_county`, `vaccines_by_county`, `masks`, and `demo`) based on `fips` and save the result as `covid_merged` (you should drop any counties that are not measured in all 4 data frames).  Determine and report how many counties were dropped from `demo` in this process, and view the header of `covid_merged`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6** Use `covid_merged` to calculate the novel case rate (per 1000 residents) for each of the weeks for all of the counties, and save these as 4 new well-named variables in `covid_merged`.  For example, `rate_w30` can mathematically be represented as `1000*(cases_30-cases_29)/population`.  Plot the histogram of the novel case rate in week 29, July 12-18, `rate_w29`, and comment on what you notice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.7** We did the steps above (and some other minimal processing) and saved the results in `covid_clean.csv` for you.  Use this data file to answer some exploratory questions and all future analyses: \n",
    "\n",
    "1. Has the overall average case rate increased from week 28 (July 5-11) to week 29 (July 12-18)?  \n",
    "2. Treating the counties as separate and equal observations: in what states did the case rate increase the most?  In what states did the case rate decrease the most (or increse the least)?  List the top 5 for each.  Do you notice any patterns in these states?\n",
    "3. Create and interpret separate visuals to display how the country case rate in week 29 relates to each of the following variables. Interpret what you see (be specific to this domain).\n",
    "\n",
    "    a. The political views in the county (as measured by the votergap in the 2020 election).\n",
    "    \n",
    "    b. The vaccination rate in the county (for week 28) (be sure to throw away the zeros as these represent unreported values).\n",
    "    \n",
    "    c. The population density of the county.\n",
    "    \n",
    "    d. Whether 50% or more of the surveyed residents in the county report that they always wore a mask in public at the time of the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "#######\n",
    "\n",
    "Clarifications:\n",
    "Q1.7.2: this is referring to the case rate increase from week 28 to week 29.\n",
    "Q1.7.3: you should investigate both forms of vaccination rates.\n",
    "    \n",
    "Q1.7 and on: the rate variables in the given covid_clean data set were not multiplied by 1000.   \n",
    "    Either keeping as is or multiplying by 1000 is fine (coefficient magnitudes are more reasonable if you multiply by 1000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 [35pts]: Regression modeling \n",
    "\n",
    "**2.1** Fit a linear regression model to predict `rate_w29` (which represent the rate of new cases in the week of July 12-18) from `rate_w28` (July 5-11). Report the 95% confidence intervals for the coefficients, and carefully interpret the coefficients (including their statistical significances).  What does this model suggest about whether the rate of COVID infection increased from week 28 to week 29?\n",
    "\n",
    "\n",
    "**2.2** Fit a linear regression model to predict `rate_w29` from `rate_w28` and `votergap20` along with the interaction between the two.  Interpret the coefficient estimates carefully (no need to mention significances).\n",
    "\n",
    "\n",
    "**2.3** Create a scatterplot of `rate_w29` vs. `rate_w28`.  Add 3 separate predicted lines from your model in 2.2 to this scatterplot: the predicted line from the model in 2.2 for counties...\n",
    "    1. where Biden was favored by 50 percentage points.\n",
    "    2. where Biden and Trump were equal\n",
    "    3. where Trump was favored by 50 percentage points.\n",
    "Interpret what you see.\n",
    "\n",
    "\n",
    "**2.4** Fit a linear regression model to assess the overall association of vaccination rate (`fully_w28`) on `rate_w29`.  Carefully interpret the results (including the statistical significance).  \n",
    "\n",
    "\n",
    "**2.5** Many counties have the value zero for `fully_w28` which really represents a missing/unreported value for vaccinationr rate.  Comment on the effect of ignoring this issue can have on the intepretations and inferences in the model in 2.4.  What would be a better way of handling this issue?\n",
    "\n",
    "\n",
    "**2.6** What factors could be confounded (whether mesured here or not) with the result seen in the model from 2.3 (list up to 3)?  Fit an appropriate linear model that controls for as many of these factors as possible (for those that are measured in this data set). Interpret the coefficient estimates from this model and compare to the results from 2.4.\n",
    "\n",
    "**2.7** What major issue could arise if you fit a model to predict `rate_w29` from `rate_w28` and `rate_w27` (or from `fully_w28` and `fully_w27`) in a linear regression model?  Suggest and explain the use of two different approaches to account for this: one approach should be based on modeling and one approach should be based on feature engineering/variable transformations (not PCA). \n",
    "\n",
    "**2.8** The test set has a response variable that is `rate_w30`.  How would you use your models to predict `rate_w29` in this section in order to predict `rate_w30` instead?  Explain.  What could go wrong in this modification?\n",
    "\n",
    "**Hint**: what should be the predictors to predict `rate_w30` instead of `rate_w29`? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Fit a linear regression model to predict `rate_w29` (which represent the rate of new cases in the week of July 12-18) from `rate_w28` (July 5-11). Report the 95% confidence intervals for the coefficients, and carefully interpret the coefficients (including their statistical significances).  What does this model suggest about whether the rate of COVID infection increased from week 28 to week 29?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Fit a linear regression model to predict `rate_w29` from `rate_w28` and `votergap20` along with the interaction between the two.  Interpret the coefficient estimates carefully (no need to mention significances).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Create a scatterplot of `rate_w29` vs. `rate_w28`.  Add 3 separate predicted lines from your model in 2.2 to this scatterplot: the predicted line from the model in 2.2 for counties...\n",
    "    1. where Biden was favored by 50 percentage points.\n",
    "    2. where Biden and Trump were equal\n",
    "    3. where Trump was favored by 50 percentage points.\n",
    "Interpret what you see.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4** Fit a linear regression model to assess the overall association of vaccination rate (`fully_w28`) on `rate_w29`.  Carefully interpret the results (including the statistical significance).  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** Many counties have the value zero for `fully_w28` which really represents a missing/unreported value for vaccinationr rate.  Comment on the effect of ignoring this issue can have on the intepretations and inferences in the model in 2.4.  What would be a better way of handling this issue?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6** What factors could be confounded (whether mesured here or not) with the result seen in the model from 2.3 (list up to 3)?  Fit an appropriate linear model that controls for as many of these factors as possible (for those that are measured in this data set). Interpret the coefficient estimates from this model and compare to the results from 2.4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7** What major issue could arise if you fit a model to predict `rate_w29` from `rate_w28` and `rate_w27` (or from `fully_w28` and `fully_w27`) in a linear regression model?  Suggest and explain the use of two different approaches to account for this: one approach should be based on modeling and one approach should be based on feature engineering/variable transformations (not PCA). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.8** The test set has a response variable that is `rate_w30`.  How would you use your models to predict `rate_w29` in this section in order to predict `rate_w30` instead?  Explain.  What could go wrong in this modification?\n",
    "\n",
    "**Hint**: what should be the predictors to predict `rate_w30` instead of `rate_w29`? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 [30pts]: Prediction modeling \n",
    "\n",
    "**3.1** Fit a well-tuned lasso model to predict `rate_w29` from the following set of predictors (along with all 2-way interactions among the main effects and all 2nd and 3rd order polynomial terms):\n",
    "\n",
    "`['rate_w28','rate_w27','dose1_w28','hispanic','minority','female','unemployed', 'income','nodegree','bachelor','inactivity','obesity','density','votergap20']`\n",
    "\n",
    "Report and explain the best choice of $\\lambda$ (a visual can help with this), your estimate of out-of-sample $R^2$, along with the number of coefficients that shrunk exactly to zero (or numerically zero) and the number that are non-zero.\n",
    "\n",
    "**3.2** Plot the trajectory curves of the main effects `['rate_w28','rate_w27','fully_w28','votergap20']` from this model: the estimates of the $\\beta$ coefficients as a function of $\\lambda$.  Interpret what you notice.\n",
    "\n",
    "**3.3** Fit a well-tuned random forest model to predict `rate_w29` from the predictors listed in 3.1.  Report your choice of the tuning parameters and briefly justify your choices (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n",
    "\n",
    "**3.4** Interpret the relationship between `rate_w29` and `dose1_w28` from the random forest model in 3.3.  Is there any evidence of interactive effects in this model involving `dose1_w28`?  How do you know?  Provide a reasonable visual (or a few visuals) to help you with these tasks and interpret what you see. \n",
    "\n",
    "**3.5** Fit a well-tuned boosting model to predict `rate_w29` from the predictors listed in 3.1.  Report your best choice of the tuning parameters and briefly justify your choice (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: again, do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n",
    "\n",
    "**3.6** Improve upon your favorite/best predictive model from 3.1, 3.3, or 3.5, by including other provided feature, by doing feature engineering, or by doing variable removal/selection.  Explain your choices.  Provide an estimate of out-of-sample $R^2$. \n",
    "\n",
    "**3.7** Evaluate your models from 3.1, 3.3, 3.5, and 3.6 on the test set (this will take some work...refer back to 2.8) using $R^2$.  How do these model's $R^2$ in test compare to the out-of-sample $R^2$ when tuning?  Explain whether this is surprising or not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Fit a well-tuned lasso model to predict `rate_w29` from the following set of predictors (along with all 2-way interactions among the main effects and all 2nd and 3rd order polynomial terms):\n",
    "\n",
    "`['rate_w28','rate_w27','dose1_w28','hispanic','minority','female','unemployed', 'income','nodegree','bachelor','inactivity','obesity','density','votergap20']`\n",
    "\n",
    "Report and explain the best choice of $\\lambda$ (a visual can help with this), your estimate of out-of-sample $R^2$, along with the number of coefficients that shrunk exactly to zero (or numerically zero) and the number that are non-zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n",
    "Corrections:\n",
    "Q3.1: please ignore/remove 'cancer' from this list of predictors.\n",
    "Q3.2: 'fully_w28' should be replaced with 'dose1_w28'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2** Plot the trajectory curves of the main effects `['rate_w28','rate_w27','fully_w28','votergap20']` from this model: the estimates of the $\\beta$ coefficients as a function of $\\lambda$.  Interpret what you notice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3** Fit a well-tuned random forest model to predict `rate_w29` from the predictors listed in 3.1.  Report your choice of the best tuning parameters and briefly justify your choice (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4** Interpret the relationship between `rate_w29` and `dose1_w28` from the random forest model in 3.3.  Is there any evidence of interactive effects in this model involving `dose1_w28`?  How do you know?  Provide a reasonable visual (or a few visuals) to help you with these tasks and interpret what you see. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5** Fit a well-tuned boosting model to predict `rate_w29` from the predictors listed in 3.1.  Report your best choice of the tuning parameters and briefly justify your choice (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: again, do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.6** Improve upon your favorite/best predictive model from 3.1, 3.3, or 3.5, by including other provided feature, by doing feature engineering, or by doing variable removal/selection.  Explain your choices.  Provide an estimate of out-of-sample $R^2$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.7** Evaluate your models from 3.1, 3.3, 3.5, and 3.6 on the test set (this will take some work...refer back to 2.8) using $R^2$.  How do these model's $R^2$ in test compare to the out-of-sample $R^2$ when tuning?  Explain whether this is surprising or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 [10pts]: Going further\n",
    "\n",
    "**4.1** Use all of the useable variables in `demo` and `masks` to create clusters of observations based on the $K$-means clustering approach.  Be sure to carefully select a reasonable choice for $K$.  Explain your choice (a visual may help with this).\n",
    "\n",
    "**4.2** Use your created clusters and incorporate them as predictor(s) into a linear regression model to assess whether the relationships you measured in the model from 2.6 depend on cluster type.  Comment on what you notice.  Determine whether out-of-sample $R^2$ has improved using this model (in comparison to the model from 2.6) based on 5-fold CV.\n",
    "\n",
    "**4.3: BONUS** Find data online to improve the prediction accuracy of your best model. Be sure to cite your source of your data and the approach you took into incorporating these new data.  Note: this is only worth up to 3 bonus points, so do not spend too much effor on this part over improving ealrier parts of the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1** Use all of the useable variables in `demo` and `masks` to create clusters of observations based on the $K$-means clustering approach.  Be sure to carefully select a reasonable choice for $K$.  Explain your choice (a visual may help with this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** Use your created clusters and incorporate them as predictor(s) into a linear regression model to assess whether the relationships you measured in the model from 2.6 depend on cluster type.  Comment on what you notice.  Determine whether out-of-sample $R^2$ has improved using this model (in comparison to the model from 2.6) based on 5-fold CV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3: BONUS** Find data online to improve the prediction accuracy of your best model. Be sure to cite your source of your data and the approach you took into incorporating these new data.  Note: this is only worth up to 3 bonus points, so do not spend too much effor on this part over improving ealrier parts of the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
